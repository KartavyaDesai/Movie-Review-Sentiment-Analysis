{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\GenAI\\RNN Movie Review\\projoneenv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sentences\n",
    "sent=[  'the glass of milk',\n",
    "     'the glass of juice',\n",
    "     'the cup of tea',\n",
    "    'I am a good boy',\n",
    "     'I am a good developer',\n",
    "     'understand the meaning of words',\n",
    "     'your videos are good',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vocabulary size\n",
    "voc_size = 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[383, 549, 916, 341],\n",
       " [383, 549, 916, 493],\n",
       " [383, 117, 916, 287],\n",
       " [146, 259, 608, 183, 628],\n",
       " [146, 259, 608, 183, 725],\n",
       " [219, 383, 340, 916, 734],\n",
       " [964, 996, 659, 183]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### One Hot Representation\n",
    "one_hot_repr=[one_hot(words,voc_size)for words in sent]\n",
    "one_hot_repr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, each word of the sentence is represented out using index out of 1000 (unique words) vocab.                               \n",
    "Below, we need each input (sentence) to be of exactly same length for model training, so we are padding it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0 383 549 916 341]\n",
      " [  0   0   0   0 383 549 916 493]\n",
      " [  0   0   0   0 383 117 916 287]\n",
      " [  0   0   0 146 259 608 183 628]\n",
      " [  0   0   0 146 259 608 183 725]\n",
      " [  0   0   0 219 383 340 916 734]\n",
      " [  0   0   0   0 964 996 659 183]]\n"
     ]
    }
   ],
   "source": [
    "sent_length=8\n",
    "embedded_docs=pad_sequences(one_hot_repr,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we are adding a embedding layer.\n",
    "1. Input Dim --> Number of Unique words or length of vocab.\n",
    "2. Output Dim --> Using how many features you want to represent a single word.\n",
    "3. Input Length --> Length of each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\GenAI\\RNN Movie Review\\projoneenv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\GenAI\\RNN Movie Review\\projoneenv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(input_dim=voc_size,output_dim=10,input_length=sent_length))\n",
    "model.compile('adam','mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 8, 10)             10000     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10000 (39.06 KB)\n",
      "Trainable params: 10000 (39.06 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.02882395,  0.00197117, -0.04019519,  0.01561208, -0.03078496,\n",
       "        -0.01849766,  0.02195524, -0.04731867,  0.04029831, -0.03399174],\n",
       "       [ 0.02882395,  0.00197117, -0.04019519,  0.01561208, -0.03078496,\n",
       "        -0.01849766,  0.02195524, -0.04731867,  0.04029831, -0.03399174],\n",
       "       [ 0.02882395,  0.00197117, -0.04019519,  0.01561208, -0.03078496,\n",
       "        -0.01849766,  0.02195524, -0.04731867,  0.04029831, -0.03399174],\n",
       "       [ 0.02882395,  0.00197117, -0.04019519,  0.01561208, -0.03078496,\n",
       "        -0.01849766,  0.02195524, -0.04731867,  0.04029831, -0.03399174],\n",
       "       [-0.01600752, -0.04901148,  0.00883685, -0.00808729,  0.01548574,\n",
       "        -0.00749417,  0.00782134,  0.00844909,  0.03585761,  0.01345693],\n",
       "       [-0.02372405,  0.01758246,  0.0286244 ,  0.02625806, -0.01910296,\n",
       "         0.02517306, -0.02423089,  0.00123686, -0.01686454,  0.04375732],\n",
       "       [ 0.03677466,  0.01583414,  0.03492576,  0.00292488,  0.00552841,\n",
       "         0.01222633,  0.02666327,  0.04681028, -0.02228265,  0.01431679],\n",
       "       [ 0.00829629,  0.03355756, -0.03039682, -0.02123867, -0.00242139,\n",
       "        -0.00274063, -0.03165625, -0.01831005,  0.00156401,  0.00494073]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
